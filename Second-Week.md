# 第二周任务细则

- 任务主题：尝试开源模型的完全微调和参数高效微调
  - 模型：LLaMA，Chinese-LLaMA, ChatGLM
  - 涉及训练方法： finetune, LoRA finetune, QLoRA finetune
  - 涉及数据集：lawgpt的 [法律数据集](http://github.com/pengxiao-song/LaWGPT )，medicalgpt的[医疗数据集](https://github.com/shibing624/MedicalGPT )


- #### 阶段一：跑通代码

- 任务目标：完成开源LLM模型的训练

  - 孙国恒：待定
    - 项目来源：

  - 余杰：待定
    - 项目来源：

  - 骆思缘：待定
    - 项目来源：



- #### 阶段二：模型训练与评测

- 任务目标：完成对训练好的模型评测，生成评测结果报告

- 评测方案：
  - 对比不同base model对训练效果的影响
  - 对比不同数据格式对训练效果的影响
  - 对比不同数据集对模型表现的影响

